{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "id": "4Xb6yqaV3CeR"
   },
   "outputs": [],
   "source": [
    "ENV = 'colab'\n",
    "ENV = 'jupyter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de **Colab** luego de instalar la libreria **matplotlib** es necesario reiniciar el environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdDXez_npHLu",
    "outputId": "2ee34573-d442-454a-b994-732a8414ee98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/adrian/anaconda3/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/adrian/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/adrian/anaconda3/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/adrian/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/adrian/anaconda3/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/adrian/anaconda3/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/adrian/anaconda3/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six in /home/adrian/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "if 'colab' in ENV:\n",
    "  !pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "id": "Nxp742TObPMp"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg\n",
    "from   six               import StringIO  \n",
    "from   IPython.display   import Image\n",
    "import pydotplus\n",
    "\n",
    "from sklearn.experimental    import enable_iterative_imputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, \\\n",
    "                                    RandomizedSearchCV\n",
    "from sklearn.impute          import IterativeImputer\n",
    "from sklearn.preprocessing   import LabelEncoder\n",
    "from sklearn.tree            import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics         import accuracy_score, confusion_matrix, \\\n",
    "                                    plot_confusion_matrix, \\\n",
    "                                    f1_score, precision_score, \\\n",
    "                                    recall_score, make_scorer, fbeta_score, \\\n",
    "                                    classification_report\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from imblearn.over_sampling    import SMOTENC\n",
    "from imblearn.under_sampling   import RandomUnderSampler\n",
    "from imblearn.pipeline         import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3HCBgi5bPMs"
   },
   "source": [
    "# Trabajo Practico 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km6W_uSwbPMt"
   },
   "source": [
    "Configuracion común de graficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "id": "JHEwBU1obPMt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.despine()\n",
    "\n",
    "tiny_size   = lambda: sns.set(rc={'figure.figsize':(5,5)})\n",
    "normal_size = lambda: sns.set(rc={'figure.figsize':(13, 8)})\n",
    "big_size    = lambda: sns.set(rc={'figure.figsize':(20,5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yiLz9QqbPMt"
   },
   "source": [
    "## Pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEH16QlSbPMt"
   },
   "source": [
    "#### A) A partir de los datos entregados, describir los atributos realizando una breve explicación de qué representan y del tipo de variable (categórica, numérica u ordinal). En caso de que haya variables no numéricas, reportar los posibles valores que toman y cuán frecuentemente lo hacen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histplot(df, column):\n",
    "    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw= {\"height_ratios\": (0.2, 1)})\n",
    "    mean=df[column].mean()\n",
    "    median=df[column].median()\n",
    "    mode=df[column].mode().values[0]\n",
    "\n",
    "    sns.boxplot(data=df, x=column, ax=ax_box)\n",
    "    ax_box.axvline(mean, color='r', linestyle='--')\n",
    "    ax_box.axvline(median, color='g', linestyle='-')\n",
    "    ax_box.axvline(mode, color='b', linestyle='-')\n",
    "\n",
    "    sns.histplot(data=df, x=column, ax=ax_hist, kde=True)\n",
    "    ax_hist.axvline(mean, color='r', linestyle='--', label=\"Media\")\n",
    "    ax_hist.axvline(median, color='g', linestyle='-', label=\"Mediana\")\n",
    "    ax_hist.axvline(mode, color='b', linestyle='-', label=\"Moda\")\n",
    "\n",
    "    ax_hist.legend()\n",
    "\n",
    "    ax_hist.set_title(f'Histograma - {column}')\n",
    "    ax_hist.set(ylabel='Frecuencia')\n",
    "    ax_hist.set(xlabel='Valores')\n",
    "    \n",
    "    ax_box.set_title(f'Boxplot - {column}')\n",
    "    ax_box.set(xlabel='')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def describe_num_var(df, column):\n",
    "    normal_size()\n",
    "    histplot(dataset, column)\n",
    "    return dataset[[column]].describe()\n",
    "\n",
    "def describe_cat_var(df, column):\n",
    "    tiny_size()\n",
    "    sns.histplot(data=dataset, y=column)\n",
    "    plt.ylabel('Valores')\n",
    "    plt.xlabel('Frecuencia')\n",
    "    plt.title(f'Histograma - {column}')\n",
    "    plt.show()\n",
    "    print(f'{column}: Tabla de frecuencias:')\n",
    "    return dataset[column].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos en dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "hM6XCCA6bPMu",
    "outputId": "03c7c2a5-e20a-45a9-bf12-5ee081d1d501"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-329-230f07a89893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'colab'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mENV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./healthcare-dataset-stroke-data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "if 'colab' in ENV:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    dataset = pd.read_csv('./healthcare-dataset-stroke-data.csv')\n",
    "else:\n",
    "    dataset = pd.read_csv('../dataset/healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KM1pX0rbPMu",
    "outputId": "add4f8b0-6db9-49c3-d86e-99eba994a56c"
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGajZ_7-bPMv"
   },
   "source": [
    "#### Genero\n",
    "\n",
    "Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5mb5h-6VbPMw",
    "outputId": "239525e9-e160-43ea-e834-ab092b2d8605"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL7T3NADbPMw"
   },
   "source": [
    "#### Edad\n",
    "\n",
    "Es una variable numerica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_num_var(dataset, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trbJH6cZbPMx"
   },
   "source": [
    "#### Hypertension\n",
    "\n",
    "Indica si eT paciente tiene hipertension o no. Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xevhn-klbPMx",
    "outputId": "fcd879d5-e874-41ba-c93d-f3b6e166867b"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'hypertension')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCRZey0xbPMy"
   },
   "source": [
    "#### Heart Disease\n",
    "\n",
    "Explica si el individio tiene una enfermedad cardiaca o no. Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4LlRaTubPMy",
    "outputId": "97f1b709-bcab-46be-b713-d79c48f461ee"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'heart_disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4-6gyAIbPMz"
   },
   "source": [
    "#### Ever Married\n",
    "\n",
    "El individuo estuvo o esta casado?. Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PnEvAmbSbPMz",
    "outputId": "9aa085d8-2b86-4626-d16f-4906af851669"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'ever_married')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9ClpQl3bPM0"
   },
   "source": [
    "#### Work Type\n",
    "\n",
    "Tipo de trabajo. Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nMwbdmFbPM0",
    "outputId": "dd2b1e8c-e852-4e0b-8346-0d2a2617f9d8"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'work_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpkN1ImUbPM0"
   },
   "source": [
    "#### Residence type\n",
    "\n",
    "Tipo de zona donde reside el invididuo. Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNf9XCcrbPM1",
    "outputId": "70628bdd-c78b-4823-c0d5-32e1d535d3da"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'Residence_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sAksWzjbPM1"
   },
   "source": [
    "#### AVG Glucose Level\n",
    "\n",
    "Nivel de grucosa medio el individuo. Es una variable numerica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_num_var(dataset, 'avg_glucose_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06PSeW0QbPM2"
   },
   "source": [
    "#### BMI\n",
    "\n",
    "Es una variable numerica. Body Mass Index (Peso / Altura^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_num_var(dataset, 'bmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPUbtq5NbPM2"
   },
   "source": [
    "#### Smoking Status\n",
    "\n",
    "Se refiere al nivel de fumador al que perteneces el individuo. Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaLpdsJ3bPM2",
    "outputId": "a80e5936-5573-49b7-f653-7e8163c1eb19"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'smoking_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLShHMrhbPM3"
   },
   "source": [
    "#### Stroke\n",
    "\n",
    "Informa si el individuo sufrio un derrame cerebral o no. Es una variable categorica con los siguentes posibles valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btjL2tjJbPM3",
    "outputId": "69fac7e9-3a8a-4f64-fce2-d8f7830958ed"
   },
   "outputs": [],
   "source": [
    "describe_cat_var(dataset, 'stroke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dN4pxTLlbPM4"
   },
   "source": [
    "#### b) Reportar si hay valores faltantes. ¿Cuántos son y en qué atributos se encuentran? En caso de haberlos, ¿es necesario y posible asignarles un valor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLnNl-vmbPM4"
   },
   "source": [
    "Antes de completar valores faltante vamos a separar el dataset en los conjuntos en dos conjuntos, development, validation y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxvJSYbWbPM4"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Funciones utilizadas para contruir un resumen de datos relevante de un objeto SetsGroup.\n",
    "#\n",
    "\n",
    "def missing_values_summary(df):\n",
    "    result = round(df.isna().sum() * 100 / len(dataset), 2)\n",
    "    result = result[result > 0]\n",
    "    result = result.apply(lambda value: f'{value}%')\n",
    "    return result \n",
    "\n",
    "def set_summary(features, target, title=None):\n",
    "    if title:\n",
    "        print(f'\\n{title}:')\n",
    "    print('- Features shape:',  features.shape)\n",
    "    print('- Target shape:',     target.shape)\n",
    "    print('- Target classes:')\n",
    "    classes = target.value_counts(normalize=True)\n",
    "    values = classes * 100\n",
    "\n",
    "    print(\"\\t- Clase {}: {:.2f} %\".format(str(classes.index[0][0]), values.values[0]))\n",
    "    print(\"\\t- Clase {}: {:.2f} %\".format(str(classes.index[1][0]), values.values[1]))\n",
    "\n",
    "    missing = missing_values_summary(features)\n",
    "\n",
    "    if missing.empty:\n",
    "        print('- Valores faltandes en features: No hay valores faltantes!')\n",
    "    else:\n",
    "        print('- Valores faltandes en features: ')\n",
    "        print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd5s4NyvbPM5"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Funciones utilizadas para consultar nombres de columnas o indices de las mismas.\n",
    "#\n",
    "\n",
    "def num_column_names(df):\n",
    "    return df.select_dtypes(include=np.number).columns\n",
    "\n",
    "def cat_column_names(df):\n",
    "    return set(df.columns) - set(num_column_names(df))\n",
    "\n",
    "def cat_column_indexes(df):\n",
    "    return [df.columns.get_loc(col_name) for col_name in cat_column_names(df)]\n",
    "\n",
    "def unique_column_values(df, column_name): \n",
    "    return df[column_name].value_counts().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uciwra3xbPM5"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SetsGroup:\n",
    "    \"\"\"\n",
    "    Representa a los conjuntos de train-validation y develoment-test. Utilizado como abstraccion comun\n",
    "    para todos los algoritmos de esta notebook.\n",
    "    \"\"\"\n",
    "    dev_features: pd.DataFrame\n",
    "    test_features: pd.DataFrame\n",
    "    dev_target: pd.DataFrame\n",
    "    test_target: pd.DataFrame\n",
    "\n",
    "    def summary(self):\n",
    "        set_summary(self.dev_features, self.dev_target, title='Conjunto de entrenamiento/desarrollo')\n",
    "        set_summary(self.test_features, self.test_target, title='Conjunto de validacion/test')\n",
    "\n",
    "    def features(self):\n",
    "        return pd.concat([self.dev_features, self.test_features])\n",
    "    \n",
    "    def feature_names(self):\n",
    "        return self.dev_features.columns\n",
    "            \n",
    "    def cat_feature_names(self):\n",
    "        return cat_column_names(self.dev_features)\n",
    "\n",
    "    def cat_feature_indexes(self):\n",
    "        return cat_column_indexes(self.dev_features)\n",
    "\n",
    "    def num_feature_names(self):\n",
    "        return num_column_names(self.dev_features)\n",
    "\n",
    "    def feature_unique_values(self, column_name):\n",
    "        return unique_column_values(self.features(), column_name)\n",
    "\n",
    "    def dev_set(self):      \n",
    "        return pd.concat([sets_group.dev_features,sets_group.dev_target], axis=1)\n",
    "\n",
    "    def keep_features(self, columns):\n",
    "        columns_to_remove = set(self.dev_features) - set(columns)\n",
    "        return self.remove_features(columns_to_remove)\n",
    "    \n",
    "    def remove_features(self, columns):\n",
    "        return SetsGroup(\n",
    "            self.dev_features.drop(columns, axis = 1),\n",
    "            self.test_features.drop(columns, axis = 1),\n",
    "            self.dev_target, \n",
    "            self.test_target\n",
    "        )\n",
    "\n",
    "    \n",
    "class DevTestSpliter:\n",
    "    \"\"\"\n",
    "    Divide un dataset en dos conjuntos con sus pares features-target. Devuelve un objecto SetsGroup.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def split(\n",
    "        dataset, \n",
    "        target_col = 'stroke', \n",
    "        test_size = 0.2,\n",
    "        random_state = 1\n",
    "    ):\n",
    "        features = dataset.loc[:, dataset.columns != target_col]\n",
    "        target   = dataset[[target_col]]\n",
    "\n",
    "        dev_features, test_features, dev_target, test_target = train_test_split(\n",
    "            features, \n",
    "            target, \n",
    "            test_size    = test_size,\n",
    "            random_state = random_state,\n",
    "            stratify     = target.values\n",
    "        )\n",
    "        return SetsGroup(dev_features, test_features, dev_target, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el databse en dos conjuntos, development y test. Un 80% para development y un 20% para test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asNjqOCgbPM6",
    "outputId": "e725eb96-335a-4052-e019-972e3300e285"
   },
   "outputs": [],
   "source": [
    "sets_group = DevTestSpliter.split(dataset, test_size = 0.2)\n",
    "\n",
    "sets_group.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMTQvupHbPM6"
   },
   "source": [
    "**Nota:** La unica variable incompleta es **BMI** y es un 3.93 + 0.55 % de valores faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF8d3Rd2bPM6"
   },
   "source": [
    "Ahora completamos valores faltantes y comparamos la distribucion de la columna **BMI** antes y despues de la imputacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o10poElsbPM6"
   },
   "outputs": [],
   "source": [
    "def impute_missing_values(df, excluded = ['id'], random_state=0):\n",
    "    \"\"\"\n",
    "    Imputa valores faltantes exceptuando las columnas excluidas.\n",
    "    \"\"\"\n",
    "    num_features = df.select_dtypes(include=np.number)\n",
    "    num_features = num_features[set(num_features.columns) - set(excluded)]\n",
    "\n",
    "    # Algoritmo basado en el algoritmo MICE de R\n",
    "    imputer = IterativeImputer(random_state=random_state) \n",
    "    imputer.fit(num_features)\n",
    "\n",
    "    imp_num_features = imputer.transform(num_features)\n",
    "\n",
    "    result_df = pd.DataFrame(\n",
    "        data    = imp_num_features, \n",
    "        columns = num_features.columns\n",
    "    )\n",
    "    for col in cat_column_names(df):\n",
    "        result_df[col] = df[col].values\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "class MissingValuesImpoter:\n",
    "    \"\"\"\n",
    "    Imputa valores sobre faltantes sobre un objeto SetsGroup, exceptuando las columnas excluidas.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, excluded = ['id'], random_state=0):\n",
    "        self.excluded     = excluded\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def impute(self, sets_group):\n",
    "        imp_dev_features  = impute_missing_values(\n",
    "            sets_group.dev_features,\n",
    "            random_state = self.random_state\n",
    "        )\n",
    "        imp_test_features = impute_missing_values(\n",
    "            sets_group.test_features,\n",
    "            random_state = self.random_state\n",
    "        )\n",
    "        return SetsGroup(\n",
    "            imp_dev_features, \n",
    "            imp_test_features, \n",
    "            sets_group.dev_target, \n",
    "            sets_group.test_target\n",
    "        )\n",
    "\n",
    "\n",
    "def compare_distributions(df1, df2, column):\n",
    "    \"\"\"\n",
    "    Util para comparar dos distribuciones graficamente.\n",
    "    \"\"\"\n",
    "    normal_size()\n",
    "    sns.kdeplot(df1[column], shade=True, color=\"r\")\n",
    "    sns.kdeplot(df2[column], shade=True, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB5usAaybPM6"
   },
   "source": [
    "Chequeamos que se hayan completado als columnas y comparamos las distribuciones para development y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FP45je9tbPM7",
    "outputId": "736ae380-a08e-4e62-b089-e870147bf9f8"
   },
   "outputs": [],
   "source": [
    "imputer = MissingValuesImpoter()\n",
    "\n",
    "imp_sets_group = imputer.impute(sets_group)\n",
    "\n",
    "imp_sets_group.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "-gSkoJi0bPM7",
    "outputId": "a56bd805-c30a-445d-ab1c-4c4d1c72b658"
   },
   "outputs": [],
   "source": [
    "compare_distributions(imp_sets_group.dev_features, sets_group.dev_features, 'bmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "FHGfORfHbPM7",
    "outputId": "7a5c9a39-9dc6-4c67-c8b1-b8d202695b43"
   },
   "outputs": [],
   "source": [
    "compare_distributions(imp_sets_group.test_features, sets_group.test_features, 'bmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UT23ATFBbPM7"
   },
   "source": [
    "Ahora la columna BMI esta completa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t26WcfFDbPM7"
   },
   "source": [
    "#### c) ¿Qué variables se correlacionan más con el evento de lesión (Stroke)? Para las cuatro más correlacionadas, realizar un gráfico en el que se pueda observar la correlación entre la variable y el stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "4uzDUs0ybPM8",
    "outputId": "08d730d5-cc9a-46e7-fa50-27b70e21338e"
   },
   "outputs": [],
   "source": [
    "def heatmap(corr, resumed=True, figsize=(10, 10), vmax=.3, square=True, annot=True, linewidths=3):\n",
    "    if resumed:\n",
    "        mask = np.zeros_like(corr)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    with sns.axes_style(\"white\"):\n",
    "        f, ax = plt.subplots(figsize=figsize)\n",
    "        ax = sns.heatmap(corr, mask=mask, vmax=vmax, square=square, annot=annot, linewidths=linewidths)\n",
    "\n",
    "        \n",
    "tmp_dataset = dataset.drop('id', axis=1)\n",
    "\n",
    "heatmap(tmp_dataset.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgAPhIFobPM8"
   },
   "source": [
    "Al parecer stroke tiene baja correlacion con las demas variables pero existe un nivel. El orden de mas correlacionada a menos es:\n",
    "\n",
    "* Age (0.25)\n",
    "* Hypertension, Heart Disease y AVG Glucose Level (0.13)\n",
    "* BMI (0.044)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7vvYrBybPM8"
   },
   "source": [
    "**Edad vs. dañoi cerebral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "Q68-sK52bPM8",
    "outputId": "f3b51d69-0a47-4daa-9bc0-648e9435abc3"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(tmp_dataset[['age', 'stroke']], height=3)\n",
    "sns.pairplot(tmp_dataset[['age','stroke']], hue=\"stroke\", height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDoiyli-bPM9"
   },
   "source": [
    "Conclusiones:\n",
    "\n",
    "* Ambas densidades estan solapadas.\n",
    "* Para age <= 23: La probabilidad de tener un daño cereblar es practicamente nula.\n",
    "* Para age > 23: La probabilidad de tener un daño cereblar es conciderable pero sigue siendo baja con relaciona a la probabilidad de no tener daño cerebral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNMd61IBbPM9"
   },
   "source": [
    "**Hipertensión vs daño cerebral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "DJ2z-O7kbPM9",
    "outputId": "31d39c59-af13-40f7-d2f2-c1baf55094ba"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(tmp_dataset[['hypertension', 'stroke']], height=3)\n",
    "sns.pairplot(tmp_dataset[['hypertension','stroke']], hue=\"stroke\", height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aj-x6qIbPM9"
   },
   "source": [
    "Conclusiones:\n",
    "    \n",
    "* Ambas densidades estan solapadas.\n",
    "* -0.2 <= hypertension <= 0.2\n",
    "    * P(Daño cerebral/ Nivel de hipertension) <<<< P(Daño cerebral/ Nivel de hipertension)\n",
    "* 0.8 <= hypertension <= 1.2\n",
    "    * P(Daño cerebral/ Nivel de hipertension) <<<< P(No Daño cerebral/ Nivel de hipertension)\n",
    "* En otros valores hay una probabilidad muy baja de daño cereblar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Psna_UMdbPM-"
   },
   "source": [
    "**Enfermedad del corazón vs daño cerebral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "rpnjkbP5bPM-",
    "outputId": "f2ec0c86-3268-42f0-ebcb-5ce835811cff"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(tmp_dataset[['heart_disease', 'stroke']], height=3)\n",
    "sns.pairplot(tmp_dataset[['heart_disease','stroke']], hue=\"stroke\", height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdIPQbGDbPM-"
   },
   "source": [
    "Conclusiones:\n",
    "    \n",
    "* Ambas densidades estan solapadas.\n",
    "* -0.2 <= heart_disease <= 0.2\n",
    "    * P(Daño cerebral/ Enfermedad del corazón) <<<< P(No Daño cerebral/ Enfermedad del corazón)\n",
    "* 0.8.5 <= hypertension <= 1.1\n",
    "    * P(Daño cerebral/ Enfermedad del corazón) <<<< P(No Daño cerebral/ Enfermedad del corazón)\n",
    "* En otros valores hay una probabilidad muy baja de daño cereblar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLZ7EpOpbPM-"
   },
   "source": [
    "**Promedio del nivel de glucosa vs daño cerebral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "hKXUEbHBbPM-",
    "outputId": "8fdd69d4-5e62-4a50-c4f1-42e7472c41e9"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(tmp_dataset[['avg_glucose_level', 'stroke']], height=3)\n",
    "sns.pairplot(tmp_dataset[['avg_glucose_level','stroke']], hue=\"stroke\", height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdqRfKBMbPM_"
   },
   "source": [
    "Conclusiones:\n",
    "    \n",
    "* Ambas densidades estan solapadas.\n",
    "* - 40 <= avg_glucose_level <= 170\n",
    "    * P(Daño cerebral/ nivel de glucosa) <<<< P(No Daño cerebral/ nivel de glucosa)\n",
    "* 0.8.5 <= hypertension <= 1.1\n",
    "    * P(Daño cerebral/ nivel de glucosa) <<<< P(No Daño cerebral/ nivel de glucosa)\n",
    "* En otros valores hay una probabilidad muy baja de daño cereblar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2kS1tqwbPM_"
   },
   "source": [
    "#### d) Se necesita saber cuáles son los indicadores que determinan más susceptibilidad a sufrir una lesión. ¿Qué atributos utilizará como variables predictoras? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qaV8HlubPM_"
   },
   "source": [
    "Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nHicTnFbPM_"
   },
   "source": [
    "#### e) ¿Se encuentra balanceado el conjunto de datos que utilizará para desarrollar el algoritmo diseñado para contestar el punto d)? En base a lo respondido, ¿qué métricas de performance reportaría y por qué? En caso de estar desbalanceado, ¿qué estrategia de balanceo utilizaría?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKAgUH1WbPM_",
    "outputId": "507729f7-1e5e-4993-ed47-d0837a17ac34"
   },
   "outputs": [],
   "source": [
    "imp_sets_group.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZQpv_IKbPM_"
   },
   "source": [
    "**Claramente esta desbalanceado** dado que es normal tener menos casos de daño cerebral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeOQVL38bPNA"
   },
   "outputs": [],
   "source": [
    "class OverUnderSampler:\n",
    "    \"\"\"\n",
    "    Se encarga de realizar un over/under sampling sobre un dataframe de features. \n",
    "    Esto nos permite balancear el dataset especificando el grado:\n",
    "\n",
    "        - over sampling: Sobre la clase minoritaria (entre 0 y 1).\n",
    "        - under sampling: Sobre la clase mayoritaria (entre 0 y 1).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        categorical_features, \n",
    "        random_state=None, \n",
    "        oversampling_strategy='auto', \n",
    "        undersampling_strategy='auto'\n",
    "    ):\n",
    "        oversampler = SMOTENC(\n",
    "            categorical_features = categorical_features, \n",
    "            random_state = random_state,\n",
    "            sampling_strategy = undersampling_strategy\n",
    "        )\n",
    "        undersampler = RandomUnderSampler(sampling_strategy = undersampling_strategy)\n",
    "        self.pipeline = Pipeline(steps=[('oversampler', oversampler), ('undersampler', undersampler)])\n",
    "\n",
    "    def perform(self, features, target):\n",
    "        bal_features, bal_target = self.pipeline.fit_resample(features.values, target.values)\n",
    "        \n",
    "        # Matrix to DataFrame\n",
    "        bal_features = pd.DataFrame(data = bal_features, columns = features.columns)\n",
    "        bal_target   = pd.DataFrame(data = bal_target,   columns = target.columns)\n",
    "\n",
    "        return bal_features, bal_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLgdstO_bPNA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SetsGroupOverUnderSampler:\n",
    "    \"\"\"\n",
    "    Utiliza el objeto OverUnderSampler para aplicar over/under sampling sobre \n",
    "    los conjuntos de features dentro de un objeto SetsGroup. \n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def createFromHps(categorical_features, hps):\n",
    "        return SetsGroupOverUnderSampler(\n",
    "            categorical_features   = categorical_features,\n",
    "            random_state           = hps.random_state, \n",
    "            oversampling_strategy  = hps.oversampling_strategy,\n",
    "            undersampling_strategy = hps.undersampling_strategy \n",
    "        )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        categorical_features,\n",
    "        random_state = None,\n",
    "        # Grado de oversampling sobre la clase minoriataria (entre 0 y 1).\n",
    "        oversampling_strategy = 0.1,\n",
    "        # Grado de undersampling sobre la clase mayoriataria (entre 0 y 1).\n",
    "        undersampling_strategy = 1\n",
    "    ):\n",
    "        self.sampler = OverUnderSampler(\n",
    "            categorical_features   = categorical_features,\n",
    "            random_state           = random_state,      \n",
    "            oversampling_strategy  = oversampling_strategy,\n",
    "            undersampling_strategy = undersampling_strategy\n",
    "        )\n",
    "\n",
    "    def perform(self, sets_group):\n",
    "        bal_dev_features, bal_dev_target = self.sampler.perform(\n",
    "            sets_group.dev_features, \n",
    "            sets_group.dev_target\n",
    "        )\n",
    "\n",
    "        return SetsGroup(\n",
    "            bal_dev_features, \n",
    "            sets_group.test_features, \n",
    "            bal_dev_target, \n",
    "            sets_group.test_target\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rq38pk4nY6-",
    "outputId": "2855684b-a475-4ccc-e3eb-c7efbfd33fa2"
   },
   "outputs": [],
   "source": [
    "sampler = SetsGroupOverUnderSampler(\n",
    "    categorical_features   = imp_sets_group.cat_feature_indexes(),\n",
    "    oversampling_strategy  = 0.1, # Grado de oversampling sobre la clase minoriataria (entre 0 y 1).\n",
    "    undersampling_strategy = 1 # Grado de undersampling sobre la clase mayoriataria (entre 0 y 1).\n",
    ")\n",
    "\n",
    "oversampled_sets_group = sampler.perform(imp_sets_group)\n",
    "\n",
    "oversampled_sets_group.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwA3ixDQbPNA"
   },
   "source": [
    "#### f) Suponiendo que es más importante detectar los casos en donde el evento ocurre. ¿Qué medida de performance utilizaría? Si utiliza Fβ-Score, ¿qué valor de β eligiría?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZpTMGSJbPNB"
   },
   "source": [
    "**Completar!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZJtYo5vbPNB"
   },
   "source": [
    "#### g) Implementar el algoritmo introducido en el punto d) utilizando árboles de decisión. En primer lugar, se deberá separar un 20% de los datos para usarlos como conjunto de evaluación (test set). El conjunto restante (80%) es el de desarrollo y es con el que se deberá continuar haciendo el trabajo. Realizar los siguientes puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xF3X_IbbPNB"
   },
   "outputs": [],
   "source": [
    "class CategoricalFeaturesEncoder:\n",
    "    \"\"\"\n",
    "    Se encarga de traducir los valores de features categoricos a numerico. \n",
    "    Esto es necesario ya que los arboles solo entiende features numericos.\n",
    "    \"\"\"\n",
    "\n",
    "    def perform(self, sets_group):\n",
    "        enc_dev_features  = sets_group.dev_features.copy()\n",
    "        enc_test_features = sets_group.test_features.copy()\n",
    " \n",
    "        for col_name in sets_group.cat_feature_names():            \n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(sets_group.feature_unique_values(col_name))\n",
    "\n",
    "            enc_test_features[col_name] = encoder.transform(sets_group.test_features[col_name].values)\n",
    "            enc_dev_features[col_name]  = encoder.transform(sets_group.dev_features[col_name].values)\n",
    "\n",
    "        return SetsGroup(\n",
    "            enc_dev_features, \n",
    "            enc_test_features, \n",
    "            sets_group.dev_target, \n",
    "            sets_group.test_target\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traducimos los valores de los features categoricas a numericos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTD2QZwLIR4-",
    "outputId": "4543526c-46d9-461d-d157-ec131fb314c6"
   },
   "outputs": [],
   "source": [
    "encoder = CategoricalFeaturesEncoder()\n",
    "\n",
    "encoded_sets_group = encoder.perform(oversampled_sets_group)\n",
    "\n",
    "encoded_sets_group.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas son funciones complementarias para mostrar un summary de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNprI7AmbPNC"
   },
   "outputs": [],
   "source": [
    "def plot_features_importance(feature_importances, column_names):\n",
    "    normal_size()\n",
    "    plt.barh(column_names, feature_importances)\n",
    "    plt.ylabel('Caracteristicas')\n",
    "    plt.xlabel('Nivel de importancia')\n",
    "    plt.title(\"Importancia de los features\")\n",
    "    plt.show()\n",
    "\n",
    "def to_tree_img(tree):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(\n",
    "        tree, \n",
    "        out_file           = dot_data,  \n",
    "        filled             = True,\n",
    "        rounded            = True,\n",
    "        special_characters = True\n",
    "    )\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    graph.write_png('tree.png')\n",
    "    return mpimg.imread('tree.png')\n",
    "\n",
    "def plot_tree(tree):\n",
    "    sns.set(rc={'figure.figsize':(15, 8)})\n",
    "    plt.title('Arbol de decisión')\n",
    "    plt.grid(False)\n",
    "    plt.imshow(to_tree_img(tree))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def cm_plot(ax, cm, title='Matriz de confusión'):     \n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        ax    = ax,\n",
    "        annot = True, \n",
    "        fmt   = 'g', \n",
    "        cmap  = 'Blues', \n",
    "        cbar  = False\n",
    "    )\n",
    "    ax.set_ylabel('Realidad')\n",
    "    ax.set_xlabel('Predicciones')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestro modelo. Este es un wrapper de un estimador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BO1KhYKobPNC"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HiperParams:\n",
    "    # Hiper parametros del modelo:\n",
    "    criterion: any        = 'entropy' \n",
    "    max_depth: int        = 5\n",
    "    min_samples_leaf: int = 1\n",
    "    ccp_alpha: float      = 0.0\n",
    "    class_weight: any     = None # 'balanced'\n",
    "    \n",
    "    # Semilla usada en todos lo algoritmos.\n",
    "    random_state: int     = 42 \n",
    "\n",
    "    # Hiper parametros para over/up sampling:\n",
    "    # Porcentaje de ejemplos duplicados en la calse minoritaria.\n",
    "    oversampling_strategy: float = 0.1\n",
    "    # Porcentaje de ejemplos removidos ne la clase mayoritaria.\n",
    "    undersampling_strategy: float = 1\n",
    "\n",
    "        \n",
    "class ModelFactory:\n",
    "    \"\"\"\n",
    "    Usado para construir distintos modelos.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def create(hps):\n",
    "        tree = DecisionTreeClassifier(\n",
    "            criterion        = hps.criterion,\n",
    "            max_depth        = hps.max_depth,\n",
    "            min_samples_leaf = hps.min_samples_leaf,\n",
    "            ccp_alpha        = hps.ccp_alpha,\n",
    "            class_weight     = hps.class_weight,\n",
    "            random_state     = hps.random_state\n",
    "        )\n",
    "        return Model(tree, hps)\n",
    "\n",
    "    def create_from(tree):\n",
    "        return Model(tree, hps)\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"\n",
    "    Es un wrapper de un estimador. permite simplificar el uso de un estimador abstrayéndonos de todo el codigo boilerplate \n",
    "    al momento de usar un estimador. Ademas permite visualizar todas las metricas de performace de una vez.\n",
    "    \"\"\"\n",
    "    def __init__(self, tree, hps):\n",
    "        self.tree = tree\n",
    "        self.hps  = hps\n",
    "\n",
    "    def fit(self, sets_group):\n",
    "        \"\"\"\n",
    "        Entrena el modelo.\n",
    "        \"\"\"\n",
    "        return self.tree.fit(\n",
    "            sets_group.dev_features.values, \n",
    "            sets_group.dev_target.values\n",
    "        )\n",
    "\n",
    "    def predict(self, features):\n",
    "        \"\"\"\n",
    "        Permite realizar una estimación.\n",
    "        \"\"\"\n",
    "        return self.tree.predict(features.values)\n",
    "\n",
    "    def evaluate(self, sets_group):\n",
    "        \"\"\"\n",
    "        Evalua el modelo en los conjuntos de entrenamiento/desarrollo y validacion/test. \n",
    "        \"\"\"\n",
    "        train_pred  = self.predict(sets_group.dev_features)\n",
    "        test_pred   = self.predict(sets_group.test_features)\n",
    "        return ModelSummary(\n",
    "            sets_group, \n",
    "            train_pred, \n",
    "            test_pred, \n",
    "            tree = self.tree, \n",
    "            hps  = self.hps,\n",
    "            features_importance = self.tree.feature_importances_\n",
    "        )\n",
    "\n",
    "class ModelSummary:\n",
    "    \"\"\"\n",
    "    Es el resultado de la evaluacion de un modelo. Este permite visualizar varias metricas \n",
    "    utiles para evaluar el desempeño del modelo.\n",
    "    \"\"\"\n",
    "    def __init__(self, sets_group, train_pred, test_pred, tree, hps, features_importance):\n",
    "        self.metrics = {\n",
    "            'train_accuracy':              accuracy_score(sets_group.dev_target.values, train_pred),\n",
    "            'train_precision':             precision_score(sets_group.dev_target.values, train_pred),\n",
    "            'train_recall':                recall_score( sets_group.dev_target.values, train_pred),\n",
    "            \"train_f1_score\":              f1_score(sets_group.dev_target.values, train_pred),\n",
    "            'train_confusion_matrix':      confusion_matrix(sets_group.dev_target.values, train_pred),\n",
    "            'train_classification_report': classification_report(sets_group.dev_target.values, train_pred),\n",
    "\n",
    "            'test_accuracy':              accuracy_score(sets_group.test_target.values, test_pred),\n",
    "            'test_precision':             precision_score(sets_group.test_target.values, test_pred),\n",
    "            'test_recall':                recall_score(sets_group.test_target.values, test_pred),\n",
    "            \"test_f1_score\":              f1_score(sets_group.test_target.values, test_pred),\n",
    "            'test_confusion_matrix':      confusion_matrix(sets_group.test_target.values, test_pred),\n",
    "            'test_classification_report': classification_report(sets_group.test_target.values, test_pred)\n",
    "        }\n",
    "        self.feature_names       = sets_group.dev_features.columns\n",
    "        self.features_importance = features_importance\n",
    "        self.tree = tree\n",
    "        self.hps  = hps\n",
    "\n",
    "        self.excluded_metics = [\n",
    "            \"train_confusion_matrix\", \n",
    "            \"test_confusion_matrix\", \n",
    "            \"train_classification_report\",\n",
    "            \"test_classification_report\",\n",
    "        ]\n",
    "\n",
    "    def plot_confusion_matrix(self):\n",
    "        sns.set(rc={'figure.figsize':(7, 4)})\n",
    "        fig = plt.figure()\n",
    "        gs = fig.add_gridspec(1, 2, hspace=0.1, wspace=0.1)\n",
    "        (ax1, ax2) = gs.subplots(sharex='col', sharey='row')\n",
    "        cm_plot(\n",
    "            ax=ax1,\n",
    "            cm=self.metrics['train_confusion_matrix'],\n",
    "            title='Entrenamiento/Desarrollo'\n",
    "        )\n",
    "        cm_plot(\n",
    "            ax=ax2,\n",
    "            cm=self.metrics['test_confusion_matrix'],\n",
    "            title='Test/Validacion'\n",
    "        )\n",
    "        fig.suptitle('Matriz de confusión')\n",
    "        plt.show()\n",
    "        \n",
    "    def show_feature_importace(self):\n",
    "        plot_features_importance(self.features_importance, self.feature_names)\n",
    "\n",
    "    def show_metrics(self):\n",
    "        print('\\nMetricas:')\n",
    "        for name in self.metrics.keys():\n",
    "            if name not in self.excluded_metics:\n",
    "                print(f'- {name}: {self.metrics[name]*100:.2f}%')\n",
    "\n",
    "    def show_classification_report(self):\n",
    "        print('- train_classification_report:\\n', self.metrics['train_classification_report'])\n",
    "        print('- test_classification_report:\\n', self.metrics['test_classification_report'])\n",
    "\n",
    "    def show_hps(self):\n",
    "        if self.hps:\n",
    "            print('\\nHiper Parametros:\\n-', self.hps)\n",
    "\n",
    "    def show(self):\n",
    "        self.show_hps()\n",
    "        self.show_metrics()\n",
    "        self.show_classification_report()\n",
    "        self.plot_confusion_matrix()\n",
    "        self.show_feature_importace()\n",
    "        plot_tree(self.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un pipeline con todas las transformaciones que necesitamos realizar al raw dataset para preparlo para el entrenamiento: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaUARJap1G-u"
   },
   "outputs": [],
   "source": [
    "def data_transform_pipeline(data, hps):\n",
    "    # Imputamos valores faltantes (MICE like)...\n",
    "    imputer = MissingValuesImpoter(random_state = hps.random_state)\n",
    "    data = imputer.impute(data)\n",
    "    \n",
    "    # Balanceamos el dataset (over/up sampling)...\n",
    "    sampler = SetsGroupOverUnderSampler.createFromHps(\n",
    "        data.cat_feature_indexes(), \n",
    "        hps\n",
    "    )\n",
    "    data = sampler.perform(data)\n",
    "\n",
    "    # Llevamos variables categoricas a numericas...\n",
    "    endcoder = CategoricalFeaturesEncoder()\n",
    "    data = endcoder.perform(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones helper utilizadas para evaloar un modelos y mostar resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, sets_group):\n",
    "    \"\"\"\n",
    "    Entrena un modelo y lo evalua en el conjunto de validacion o test. \n",
    "    Luego muestra un summary de metricas y graficos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Entrenamos el modelos...\n",
    "    model.fit(sets_group)\n",
    "    \n",
    "    # Evaluamos el modelo sobre el conjuntos de validación.\n",
    "    summary = model.evaluate(sets_group)\n",
    "    \n",
    "    # Mostramos el resumen de metricas...\n",
    "    summary.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_estimator(estimator, sets_group):\n",
    "    # Creamos el model wrapper para el estimador...\n",
    "    model = ModelFactory.create_from(estimator)\n",
    "\n",
    "    return evaluate_model(model, sets_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un primer modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpUN03FdbPNC"
   },
   "outputs": [],
   "source": [
    "hiper_params = [\n",
    "    # Usamos todos los valores por defecto...\n",
    "    HiperParams(\n",
    "        # Hiper parametros del modelo:\n",
    "        criterion        = 'entropy',\n",
    "        max_depth        = 2,\n",
    "        min_samples_leaf = 300,\n",
    "\n",
    "        # Hiper parametros para over/up sampling:\n",
    "        # Porcentaje de ejemplos duplicados en la calse minoritaria.\n",
    "        oversampling_strategy = 0.1,\n",
    "\n",
    "        # Porcentaje de ejemplos removidos ne la clase mayoritaria.\n",
    "        undersampling_strategy = 0.5\n",
    "    )\n",
    "]\n",
    "\n",
    "for hps in hiper_params:\n",
    "    # Pipeline de trasnformación de datos...\n",
    "    data = data_transform_pipeline(sets_group, hps)\n",
    "\n",
    "    # Resumen de estrutura de los datos...\n",
    "    data.summary()\n",
    "\n",
    "    # Creamos el modelo (Arbol de decisión)...\n",
    "    model = ModelFactory.create(hps)\n",
    "    \n",
    "    evaluate_model(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykBZ1JFsbPND"
   },
   "source": [
    "#### g.1) Armar conjuntos de entrenamiento y validación con proporción 80-20 del conjunto de desarrollo de forma aleatoria. Usar 50 semillas distintas y realizar un gráfico de caja y bigotes que muestre cómo varía la métrica elegida en c) en esas 50 particiones distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXDSqSQ79W-o"
   },
   "outputs": [],
   "source": [
    "class MetricsComparePlot:\n",
    "    \"\"\"\n",
    "    Acumula un log de metricas para luego graficar un box plot comparativo.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.accs = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "        self.f1s = []\n",
    "\n",
    "    def add(self, y_val,y_pred_val):\n",
    "        self.accs.append(accuracy_score(y_val,y_pred_val))\n",
    "        self.precisions.append(precision_score(y_val,y_pred_val))\n",
    "        self.recalls.append(recall_score(y_val,y_pred_val))\n",
    "        self.f1s.append(f1_score(y_val,y_pred_val))\n",
    "\n",
    "    def plot(self):\n",
    "        all_metrics = self.accs + self.precisions + self.recalls + self.f1s\n",
    "        metric_labels = ['Accuracy']*len(self.accs) + ['Precision']*len(self.precisions) + ['Recall']*len(self.recalls) + ['F1 Score']*len(self.f1s)\n",
    "        sns.set_context('talk')\n",
    "        plt.figure(figsize=(15,8))\n",
    "        sns.boxplot(metric_labels, all_metrics)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearmamos el dataset de dev (feat + tgt) y vuelvemos a correr train/test split, ya que el primero separó dev + val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "e3xV0j6Dpmfz",
    "outputId": "bc888846-1c0d-401d-c39a-0169fa1a8f3c"
   },
   "outputs": [],
   "source": [
    "dev_concat = sets_group.dev_set()\n",
    "\n",
    "n_seeds   = 50\n",
    "test_size = 0.2\n",
    "plotter   = MetricsComparePlot()\n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    hps = HiperParams(random_state = seed)\n",
    "\n",
    "    sets_group_dev = DevTestSpliter.split(\n",
    "        dev_concat, \n",
    "        test_size = test_size, \n",
    "        random_state = hps.random_state\n",
    "    )\n",
    "\n",
    "    encoded_sets_group_dev = data_transform_pipeline(sets_group_dev, hps)\n",
    "\n",
    "    arbol = ModelFactory.create(hps)\n",
    "    arbol = arbol.fit(encoded_sets_group_dev)\n",
    "    y_pred_val = arbol.predict(encoded_sets_group_dev.test_features)\n",
    "\n",
    "    plotter.add(encoded_sets_group_dev.test_target, y_pred_val)\n",
    "\n",
    "plotter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d6YBNB2bPND"
   },
   "source": [
    "#### g.2) Usar validación cruzada de 50 iteraciones (50-fold cross validation). Realizar un gráfico de caja y bigotes que muestre cómo varía la métrica elegida en esas 50 particiones distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6sLNnKhhPDu"
   },
   "outputs": [],
   "source": [
    "def search_best_model(sets_group, params_grid, n_splits, n_iter):\n",
    "    \"\"\"\n",
    "    Se ocupa de buscar el mejor estimador para una grilla de hiper parametros.\n",
    "    \"\"\"\n",
    "    print('\\nRandom Search Hiper-params:', params_grid)\n",
    "\n",
    "    scoring = make_scorer(f1_score)\n",
    "    # scoring = make_scorer(fbeta_score, beta=0.1)\n",
    "\n",
    "    randomcv = RandomizedSearchCV(\n",
    "        estimator           = DecisionTreeClassifier(),\n",
    "        param_distributions = params_grid,\n",
    "        scoring             = scoring,\n",
    "        cv                  = StratifiedKFold(n_splits=n_splits),\n",
    "        n_iter              = n_iter,\n",
    "        return_train_score  = True\n",
    "    )\n",
    "    randomcv.fit(\n",
    "        sets_group.dev_features.values,\n",
    "        sets_group.dev_target.values\n",
    "    )\n",
    "    \n",
    "    random_cv_results = pd.DataFrame(randomcv.cv_results_)\n",
    "    print('Models Count:', random_cv_results.shape[0])\n",
    "\n",
    "    return randomcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMvFA0ULcmv0"
   },
   "outputs": [],
   "source": [
    "def plot_randomcv_metrics(randomcv_result, metrics):\n",
    "    df = pd.DataFrame(randomcv_result.cv_results_)\n",
    "    normal_size()\n",
    "    for metric in metrics:\n",
    "        plt.plot(df[metric],  linestyle='-', marker='o', label=metric)\n",
    "    plt.legend()\n",
    "    plt.title('Score de entranamiento vs score de validación')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_randomcv_score(randomcv_result):\n",
    "    plot_randomcv_metrics(randomcv_result, metrics=['mean_train_score','mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "YKLoVTOQpySK",
    "outputId": "11e2993d-2d90-46d9-bf92-7381f6467396"
   },
   "outputs": [],
   "source": [
    "n_splits = 20\n",
    "\n",
    "hps = HiperParams(\n",
    "    # Hiper parametros para over/up sampling:\n",
    "    # Porcentaje de ejemplos duplicados en la calse minoritaria.\n",
    "    oversampling_strategy = 0.1,\n",
    "    # Porcentaje de ejemplos removidos ne la clase mayoritaria.\n",
    "    undersampling_strategy = 0.5\n",
    ")\n",
    "\n",
    "encoded_sets_group_dev = data_transform_pipeline(sets_group_dev, hps)\n",
    "\n",
    "encoded_sets_group_dev.summary()\n",
    "\n",
    "randomcv_sin_poda = search_best_model(\n",
    "    encoded_sets_group_dev,\n",
    "    params_grid = {\n",
    "        'criterion': ['gini','entropy'],\n",
    "        'max_depth': list(range(1, 10)),\n",
    "        'min_samples_leaf': list(range(1, 50))\n",
    "    }, \n",
    "    n_splits = n_splits,\n",
    "    n_iter = 50\n",
    ")\n",
    "plot_randomcv_score(randomcv_sin_poda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "e8PFbjTjdSVI",
    "outputId": "27552eff-85b5-4d6a-996b-09d091f65cbe"
   },
   "outputs": [],
   "source": [
    "random_cv_results = pd.DataFrame(randomcv_sin_poda.cv_results_)\n",
    "random_cv_results[random_cv_results.params == randomcv_sin_poda.best_params_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "GEwsnTE_pyYT",
    "outputId": "b23197e1-887c-471c-da87-92a9f151524a"
   },
   "outputs": [],
   "source": [
    "metric_labels = []\n",
    "metric_labels = ['F1 Score']*n_splits\n",
    "\n",
    "accs_kfold = []\n",
    "for x in range(0,n_splits):\n",
    "  col = 'split' + str(x) + '_test_score'\n",
    "  accs_kfold.append(random_cv_results[col].values[0])\n",
    "\n",
    "hue = []\n",
    "hue = ['Arbol1']*n_splits\n",
    "sns.set_context('talk')\n",
    "normal_size()\n",
    "sns.boxplot(metric_labels,accs_kfold,hue=hue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UlOsS_KbPND"
   },
   "source": [
    "#### h) Graficar el árbol de decisión con mejor performance encontrado en el punto g2). Analizar el árbol de decisión armado (atributos elegidos y decisiones evaluadas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hIF_za85SSdv",
    "outputId": "ee684726-814c-4bd0-afe8-c61feb356667"
   },
   "outputs": [],
   "source": [
    "evaluate_estimator(\n",
    "    estimator  = randomcv_sin_poda.best_estimator_,\n",
    "    sets_group = encoded_sets_group_dev\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-uUf3qbbPNE"
   },
   "source": [
    "#### i) Usando validación cruzada de 10 iteraciones (10-fold cross validation), probar distintos valores de α del algoritmo de poda mínima de complejidad de costos (algoritmo de poda de sklearn). Hacer gráficos de la performance en validación y entrenamiento en función del α. Explicar cómo varía la profundidad de los árboles al realizar la poda con distintos valores de α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xY8qa4hr2bl"
   },
   "outputs": [],
   "source": [
    "def to_params_grid(hiper_params):\n",
    "    params_grid = {}\n",
    "    for name in hiper_params.keys():\n",
    "        params_grid[name] = [hiper_params[name]]\n",
    "    return params_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos como parametros **fijos** todos los hiperparametro del el mejor modelo entrado en el punto anterior y agregamos **ccp_alpha** para buscar el valor que mejor performe la metrica seleccioanda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 760
    },
    "id": "dzDhUBJQYeLc",
    "outputId": "c4d00b74-a452-4b32-dea4-245a4c491ba6"
   },
   "outputs": [],
   "source": [
    "params_grid = to_params_grid(randomcv_sin_poda.best_params_)\n",
    "params_grid['ccp_alpha'] = np.linspace(0, 0.3, 100)\n",
    "\n",
    "randomcv_con_poda = search_best_model(\n",
    "    encoded_sets_group_dev,\n",
    "    params_grid = params_grid, \n",
    "    n_splits    = 10,\n",
    "    n_iter      = 5\n",
    ")\n",
    "\n",
    "plot_randomcv_score(randomcv_con_poda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24_SJzGlbPNE"
   },
   "source": [
    "#### j) Evaluar en el conjunto de evaluación, el árbol correspondiente al α que maximice la performance en el conjunto de validación. Comparar con el caso sin poda (α=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhhG2w6At7f-"
   },
   "source": [
    "**Modelo con poda:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jk30vqcAjEvu",
    "outputId": "1d3defbe-d08c-4bb1-907b-a3698fcc6ce7"
   },
   "outputs": [],
   "source": [
    "trained_best_model = evaluate_estimator(\n",
    "    estimator  = randomcv_con_poda.best_estimator_,\n",
    "    sets_group = encoded_sets_group_dev\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgQBbax5uH-N"
   },
   "source": [
    "**Modelo sin poda**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HjgB_P_zuDpg",
    "outputId": "e041f063-ffea-42fd-a27e-93d37e6701d7"
   },
   "outputs": [],
   "source": [
    "evaluate_estimator(\n",
    "    estimator  = randomcv_sin_poda.best_estimator_,\n",
    "    sets_group = encoded_sets_group_dev\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH9O_YiYbPNE"
   },
   "source": [
    "#### k) Para el árbol sin poda, obtener la importancia de los descriptores usando la técnica de eliminación recursiva. Reentrenar el árbol usando sólo los 3 descriptores más importantes. Comparar la performance en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestFeaturesSelector:\n",
    "    \"\"\"\n",
    "    Se encarga de encontrar de encontrar y rankear los mejores features de desarrollo dentro objeto SetsGroup.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator,\n",
    "        folds_count            = 10,\n",
    "        min_features_to_select = 3,\n",
    "        step                   = 1,\n",
    "        scoring                =  make_scorer(f1_score)\n",
    "    ):\n",
    "        self.selector = RFECV(\n",
    "            estimator = estimator,\n",
    "            step      = step, \n",
    "            cv        = StratifiedKFold(folds_count),\n",
    "            scoring   = scoring,\n",
    "            # Numero minimo de features\n",
    "            min_features_to_select = min_features_to_select\n",
    "        )\n",
    "        self.min_features_to_select = min_features_to_select\n",
    "\n",
    "    def perform(self, set_group):\n",
    "        self.selector.fit(set_group.dev_features, set_group.dev_target)\n",
    "        return BestFeaturesSelectorSummary(\n",
    "            self.selector, \n",
    "            self.min_features_to_select,\n",
    "            set_group\n",
    "        )\n",
    "\n",
    "def postions(values, equal_to):\n",
    "    \"\"\"\n",
    "    Devuelve las posiciones en el array para los valores que sea igaules a equal_to.\n",
    "    \"\"\"\n",
    "    return [index for index, value in enumerate(values) if value == equal_to]\n",
    "\n",
    "class BestFeaturesSelectorSummary:\n",
    "    \"\"\"\n",
    "    Es el resultado de realizar una selección de features con el objeto BestFeaturesSelector.\n",
    "    Este contiene el resultado de este analisis ademas de metricas a modo de summary.\n",
    "    \"\"\"\n",
    "    def __init__(self, selector, min_features_to_select, set_group): \n",
    "        self.selector = selector\n",
    "        self.min_features_to_select = min_features_to_select\n",
    "        self.set_group = set_group\n",
    "    \n",
    "    def plot(self):\n",
    "        print(\"Numero optimo de caracteristicas: %d\\n\" % self.selector.n_features_)\n",
    "        print(\"Mejores caracteristicas: %s\\n\" % self.best_feature_names())\n",
    "        normal_size()\n",
    "        plt.figure()\n",
    "        plt.xlabel(\"Cantidad de caracteristicas\")\n",
    "        plt.ylabel(\"Metricas usada para cross validation\")\n",
    "        plt.plot(\n",
    "            range(self.min_features_to_select,\n",
    "            len(self.selector.grid_scores_) + self.min_features_to_select),\n",
    "            self.selector.grid_scores_\n",
    "        )\n",
    "        plt.show()\n",
    "    \n",
    "    def best_features_index(self):\n",
    "        return postions(self.selector.ranking_, equal_to=1)\n",
    "    \n",
    "    def best_feature_names(self):\n",
    "        return self.set_group.feature_names()[self.best_features_index()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo sin poda usando los conjuntos TRAIN + VAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = BestFeaturesSelector(\n",
    "    estimator   = randomcv_sin_poda.best_estimator_,\n",
    "    folds_count = 10,\n",
    "    min_features_to_select = 3\n",
    ")\n",
    "\n",
    "summary = selector.perform(encoded_sets_group_dev)\n",
    "\n",
    "summary.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos unicamente con los features mas importantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_group = encoded_sets_group_dev.keep_features(summary.best_feature_names())\n",
    "print(sets_group.feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_estimator(\n",
    "    estimator  = randomcv_sin_poda.best_estimator_,\n",
    "    sets_group = sets_group\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo sin poda usando los conjuntos DEVELOPMENT + TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = BestFeaturesSelector(\n",
    "    estimator   = randomcv_sin_poda.best_estimator_,\n",
    "    folds_count = 10\n",
    ")\n",
    "\n",
    "summary = selector.perform(encoded_sets_group)\n",
    "\n",
    "summary.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos unicamente con los features mas importantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_group = encoded_sets_group.keep_features(summary.best_feature_names())\n",
    "print(sets_group.feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_estimator(\n",
    "    estimator  = randomcv_sin_poda.best_estimator_,\n",
    "    sets_group = sets_group\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tp1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
